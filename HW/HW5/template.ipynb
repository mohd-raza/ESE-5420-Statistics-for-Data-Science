{"cells":[{"cell_type":"markdown","metadata":{"id":"gABaLz7d5wvM"},"source":["# ESE 4020/5420 - Problem Set \\#5\n","**Author:** `Your Name Goes Here`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gmV5vwO1B9EP"},"outputs":[],"source":["# These are the only imports you can use for Question 1\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"naw5rUrwMkTR"},"source":["## Question 1: Logistic Regression from Scratch\n"]},{"cell_type":"markdown","metadata":{"id":"bgCxN_AbdyZz"},"source":["Load the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3V_8vuJtMl6N"},"outputs":[],"source":["# TO-DO: Use np.load(...) to read the data then assign the data to X, and the labels to y.\n","X = np.load('...')\n","y = np.load('...')"]},{"cell_type":"markdown","metadata":{"id":"Obtzw9AgdyZ0"},"source":["Visualize one input data point as an image for each of label 0 and label 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9PT2a6vOOLV"},"outputs":[],"source":["# TO-DO: The data should be reshaped back to [28 x 28] to be able to visualize it using plt.imshow()\n"]},{"cell_type":"markdown","metadata":{"id":"hAbXKvaedyZ1"},"source":["Since the data is in between 0 to 255, normalize the data to [0, 1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KIt2Jk8DPB8s"},"outputs":[],"source":["# TO-DO: Normalize the data\n"]},{"cell_type":"markdown","metadata":{"id":"WcydoAksdyZ1"},"source":["Set $y_i = +1$ for images originally labeled 0, and $y_i = -1$ for images originally labeled 1."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3q9I2VXBPgBK"},"outputs":[],"source":["# TO-DO: Convert labels\n"]},{"cell_type":"markdown","metadata":{"id":"aBnqXTlDdyZ2"},"source":["Split the data randomly into train and test with a ratio of 80:20."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1DEBZcVgQWtt"},"outputs":[],"source":["# TO-DO: Create function that takes in (X,y) and splits the data by returning (X_train, y_train, X_test, y_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"htvnYXWHij4D"},"outputs":[],"source":["# TO-DO: Call your function to perform the Train-Test Split on our data\n"]},{"cell_type":"markdown","metadata":{"id":"cAnLOHcsdyZ4"},"source":["Initialize the coefficients $\\beta_0^{(1)}$, **$\\vec{\\beta}$** using a Normal Distribution of mean 0 and variance 1.\n","\n","For **$\\beta_1$**, initialize all $d$ entries to be $N(0,1)$)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kHWwtN8UdyZ4"},"outputs":[],"source":["# TO-DO: Initialize all d entries to be sampled from a standard normal distribution\n","B = ...\n","B_0 = ..."]},{"cell_type":"markdown","metadata":{"id":"yfOf_y8PdyZ4"},"source":["Compute the loss function\n","$$L(\\beta_0^{(1)}, \\vec{\\beta}) = \\frac{1}{m}\\sum_{i=1}^m \\text{ln}(1+e^{-y_i (\\beta_0 + \\sum_{j=1}^d \\beta_{j}x_{i,j})})$$\n","where $x_{i,j}$ is the $j$-th of entry data point $\\vec{\\textbf{x}_i}$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rCwBq1gCdyZ4"},"outputs":[],"source":["# TO DO: Helper function to compute loss\n","def compute_loss(data, labels, B, B_0):\n","\n","    ..."]},{"cell_type":"markdown","metadata":{"id":"xUCS4JaAdyZ4"},"source":["Compute the gradients of the loss function\n","\n","$$\\frac{\\partial L}{\\partial \\beta_0} = d\\beta_0 = -\\frac{1}{m}\\sum_{i=1}^m \\frac{e^{-y_i \\cdot (\\beta_0 + \\vec{\\beta^T} \\vec{x_{i}})}}{1 + e^{-y_i (\\beta_0 + \\vec{\\beta^T} \\vec{x_{i}})}} y_i$$\n","$$\\nabla_\\beta L = d\\vec{\\beta} = -\\frac{1}{m}\\sum_{i=1}^m \\frac{e^{-y_i \\cdot (\\beta_0 + \\vec{\\beta^T} \\vec{x_{i}})}}{1 + e^{-y_i (\\beta_0 + \\vec{\\beta^T} \\vec{x_{i}})}} y_i x_i$$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QfjEcne6dyZ5"},"outputs":[],"source":["# TO-DO: Helper function to compute loss\n","def compute_gradients(data, labels, B, B_0):\n","\n","    ...\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WWWkXnKodyZ5"},"source":["Update the parameters using gradient updates from the train set as:\n","$$\\beta_j \\leftarrow \\beta_j - 0.05 \\cdot d\\beta_j$$\n","$$\\beta_0 \\leftarrow \\beta_0 - 0.05 \\cdot d\\beta_0$$"]},{"cell_type":"markdown","metadata":{"id":"ntyasgjBdyZ5"},"source":["Repeat the process for 50 iterations. You should save your results for each of the 50 epochs in `accuracy_hist`, `train_loss_hist`, and `test_loss_hist`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"93Pz9mqjdyZ5"},"outputs":[],"source":["# TO-DO: Write your code below. This will be the longest part!\n"]},{"cell_type":"markdown","metadata":{"id":"gLsb0ZJboJaM"},"source":["Plot your training and testing loss curves side-by-side below by running the plotting code given below. You don't need to modify these two cells."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TbLlmzdgdyZ6"},"outputs":[],"source":["fig = plt.figure(figsize = (15,6))\n","\n","# Plot Loss Function\n","ax1 = fig.add_subplot(121)\n","ax1.plot(train_loss_hist);\n","ax1.set_title(\"Training Loss over each Iteration\", fontsize = 16);\n","ax1.set_xlabel(\"Iteration\");\n","ax1.set_ylabel(\"Loss\");\n","\n","# Plot Accuracy Function\n","ax2 = fig.add_subplot(122)\n","ax2.plot(test_loss_hist);\n","ax2.set_title(\"Testing Loss over each Iteration\", fontsize = 16);\n","ax2.set_xlabel(\"Iteration\");\n","ax2.set_ylabel(\"Loss\");"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J5oPLGCldyZ6"},"outputs":[],"source":["# Plot your accuracy curve below by running the template code below\n","plt.plot(accuracy_hist);\n","plt.title(\"Testing Accuracy over each Iteration\");\n","plt.xlabel(\"Iteration\");\n","plt.ylabel(\"Accuracy\");"]},{"cell_type":"markdown","metadata":{"id":"KEtgsGDZo1uX"},"source":["## Congratulations!!! Now convert this to `.pdf`!\n","\n","You're done with all the coding questions! Now convert this `.ipynb` into a `.pdf` neatly to prevent cells and figures from splitting across pages and getting weirdly truncated by following these steps:\n","\n","1. Download your Colab notebook as an `.ipynb` file to save locally on your computer\n","2. Open it locally via Jupyter Notebook\n","3. Go to “print preview” mode\n","4. Print to `.pdf` from there.\n","5. Merge this PDF with your handwritten notes. You can use https://smallpdf.com/merge-pdf\n","\n","Leave enough time to ask for help if you're stuck so you don't get hit with the Late Penalty!"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":0}
